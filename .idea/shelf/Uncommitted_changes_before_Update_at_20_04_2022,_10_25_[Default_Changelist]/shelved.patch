Index: AN_analyses.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import argparse\nimport spacy\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom wordfreq import word_frequency\n\n# Pandas settings\npd.set_option('display.max_columns', None)\n\n# Run with arguments, for example: --exercise 3\nparser = argparse.ArgumentParser()\nparser.add_argument('--data_dir', default='data/preprocessed/train/', help=\"Directory containing the dataset\")\nparser.add_argument('--data_dir_stat', default='data/original/english/', help=\"Directory containing the Wiki dataset\")\nparser.add_argument('--exercise', default='3')\n\n#Figure settings\nfig_folder = \"images/\"\n\ndef get_words_data(text):\n    words, lens = [], []\n    for token in text:\n        if token.is_punct != True:\n            words.append(token.text)\n            lens.append(len(token.text))\n    if len(lens) != 0:\n        avg_len = sum(lens) / len(lens)\n    else:\n        avg_len = 0\n    return len(words), avg_len\n\ndef get_average_num_words(text):\n    sentences = list(text.sents)\n    avg = []\n    for sent in sentences:\n        avg.append(get_words_data(sent)[0])\n    return sum(avg) / len(avg)\n\ndef tokenization():\n    # The number of tokens such as words, numbers, punctuation marks etc.\n    tokens = [token.text for token in doc]\n    print(\"Number of tokens: %i\" % len(tokens))\n    # The number of unique tokes\n    print(\"Number of types: %i\" % len(set(tokens)))\n    words_data = get_words_data(doc)\n    # The number of words after removing stopwords and punctuations\n    print(\"Number of words: %i\" % words_data[0])\n    # The number of average words per sentence\n    print(\"Average number of words per sentence: %.2f\" % get_average_num_words(doc))\n    print(\"Average word length: %.2f\" % words_data[1])\n    print(\"\\n\")\n\ndef words():\n    tags = [token.tag_ for token in doc]\n\n    # Get 10 most frequent tags\n    unique_elements, frequency = np.unique(tags, return_counts=True)\n    sorted_indexes = np.argsort(frequency)[::-1]\n    fgPOS = unique_elements[sorted_indexes][:10]\n    freq = frequency[sorted_indexes][:10]\n\n    freq_tokens, infreq_tokens, uPOS = [], [], []\n    for tag in fgPOS:\n        # Get most frequent and infrequent words with that tag\n        words = [token.text for token in doc if token.tag_ == tag]\n        words_tally = Counter(words)\n        freq_tokens.append(', '.join([word for word, cnt in words_tally.most_common(3)]))\n        infreq_tokens.append(words_tally.most_common()[-1][0])\n        # Get POS for that tag\n        uPOS.append(next(token.pos_ for token in doc if token.tag_ == tag))\n\n    # Build DataFrame for output\n    word_class = pd.DataFrame({'Fg POS-tag': fgPOS,\n                               'Universal POS-tag': uPOS,\n                               'Occurrences': freq[:10],\n                               'Relative Tag Freq(%)': np.around(freq[:10] / len(tags),2),\n                               '3 most frequent tokens': freq_tokens,\n                               'Example infrequent token': infreq_tokens})\n    print(word_class)\n    print(\"\\n\")\n\ndef get_ngram(text, ngram):\n    temp = zip(*[text[i:] for i in range(0, ngram)])\n    return [' '.join(ngram) for ngram in temp]\n\ndef ngrams():\n    tokens = [token.text for token in doc]\n    bigram_tokens = Counter(get_ngram(tokens, 2))\n    trigram_tokens = Counter(get_ngram(tokens, 3))\n\n    pos = [token.tag_ for token in doc]\n    bigram_pos = Counter(get_ngram(pos, 2))\n    trigram_pos = Counter(get_ngram(pos, 3))\n\n    #TO-DO: Maike, Giulia - speak about Maike taking unigrams for bigrams and bigrams for trigrams\n    print('Token bigrams: ', bigram_tokens.most_common(3))\n    print('Token trigrams: ', trigram_tokens.most_common(3))\n    print('POS bigrams: ', bigram_pos.most_common(3))\n    print('POS trigrams:', trigram_pos.most_common(3))\n    print('\\n')\n\ndef lemmatization():\n    tokens = {}\n    sentences = {}\n    for sentence in doc.sents:\n        for token in sentence:\n            if (token.lemma_ != token.text.lower()):  # then there is an inflection\n                if token.lemma_ not in tokens.keys():\n                    tokens[token.lemma_] = [token.text]\n                    sentences[token.lemma_] = [sentence]\n                else:\n                    # if infliction did not exist, add to list\n                    if token.text not in tokens[token.lemma_]:\n                        tokens[token.lemma_].append(token.text)\n                        sentences[token.lemma_].append(sentence)\n                if len(tokens[token.lemma_]) == 3:\n                    print('Lemma: ', token.lemma_)\n                    print('Inflected Forms: ', tokens[token.lemma_])\n                    print('Example sentences for each form: ', sentences[token.lemma_])\n                    print('\\n')\n                    return\n\ndef ner():\n    ne, ne_labels = [], []\n    for ent in doc.ents:\n        ne.append(ent.text)\n        ne_labels.append(ent.label_)\n    print('Number of named entities: ', len(ne))\n    #TO-DO Why is Maike counting the unique NE?\n    print('Number of unique named entities: ', len(set(ne)))\n    print('Number of different entity labels: ', len(set(ne_labels)))\n\n    for i, sentence in enumerate(doc.sents):\n        print(sentence)\n        print('Named entities: ', [ent.text for ent in sentence.ents])\n        if i==4: break\n\ndef process_wiki():\n    global wiki_data\n    wiki_data.columns = ['target', 'cna', 'cnna', 'bin', 'prob']\n    wiki_data['cannotators'] = wiki_data.cna + wiki_data.cnna\n    wiki_data['tokens'] = wiki_data.target.apply(lambda x: nlp(x))\n    wiki_data['ntokens'] = wiki_data.tokens.apply(lambda x: len(x))\n\ndef explore_dataset():\n    text = 'Both China and the Philippines flexed their muscles on Wednesday.'\n    target = 'flexed their muscles'\n    target_pos = text.find(target)\n    print('Start and offset for target \"' + target + '\": ' + str(target_pos) + ' ' + str(target_pos + len(target)))\n\n    target = 'flexed'\n    target_pos = text.find(target)\n    print('Start and offset for target \"' + target + '\": ' + str(target_pos) + ' ' + str(target_pos + len(target)))\n\ndef basic_stat():\n    #7746 in total\n    print('Number of instances labeled with 0: %i' % len(wiki_data[wiki_data.bin == 0]))\n    print('Number of instances labeled with 1: %i' % len(wiki_data[wiki_data.bin == 1]))\n    print('Min, max, median, mean, and stdev of the probabilistic label: %.2f, %.2f, %.2f, %.2f, %.2f' % (\n        wiki_data.prob.min(), wiki_data.prob.max(), wiki_data.prob.median(), wiki_data.prob.mean(), wiki_data.prob.std()\n    ))\n    print('Number of instances consisting of more than one token: %i' % len(wiki_data[wiki_data.ntokens != 1]))\n    print('Maximum number of tokens for an instance: %i' % max(wiki_data.ntokens))\n\ndef save_scatter(x, y, xlabel, ylabel, title, plot_name):\n    if not os.path.exists(fig_folder):\n        os.makedirs(fig_folder)\n    fig = plt.figure(figsize=(8, 5))\n    plt.scatter(x, y)\n    plt.title(title)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.show()\n    fig.savefig(fig_folder + plot_name, dpi=fig.dpi)\n\ndef ling_char():\n    global wiki_data\n    # Filter to take only #tokens = 1 and at least one complex annotation\n    wiki_data = wiki_data[(wiki_data.ntokens == 1) & (wiki_data.cannotators > 1)]\n    wiki_data['len_tokens'] = wiki_data.tokens.apply(lambda x: len(x[0]))\n    wiki_data['freq_tokens'] = wiki_data.tokens.apply(lambda x: word_frequency(str(x[0]), 'en'))\n    wiki_data['pos_tag'] = wiki_data.tokens.apply(lambda x: x[-1].pos_)\n    print(len(wiki_data))\n\n    print('Pearson correlation length and complexity: ', round(wiki_data.len_tokens.corr(wiki_data.prob),2))\n    print('Pearson correlation frequency and complexity: ', round(wiki_data.freq_tokens.corr(wiki_data.prob), 2))\n\n    save_scatter(wiki_data.len_tokens, wiki_data.prob, 'length of tokens', 'probabilistic complexity',\n                 'Probabilistic complexity by length of tokens', 'len_tokens_prob_scatter.png')\n    save_scatter(wiki_data.freq_tokens, wiki_data.prob, 'frequency of tokens', 'probabilistic complexity',\n                 'Probabilistic complexity by frequency of tokens', 'freq_tokens_prob_scatter.png')\n    save_scatter(wiki_data.pos_tag, wiki_data.prob, 'POS tag', 'probabilistic complexity',\n                 'Probabilistic complexity by POS tags', 'pos_tags_prob_scatter.png')\n\nif __name__ == '__main__':\n    \"\"\"\n        `Data Analysis`\n    \"\"\"\n    # Load the parameters\n    args = parser.parse_args()\n    args_dict = vars(args)\n\n    if args.exercise == 'all':\n        exercise = range(1, 9)\n    else:\n        exercise = [int(args.exercise)]\n\n    # Load the data\n    data_file = open(args.data_dir + \"sentences.txt\", encoding=\"utf8\", errors='ignore')\n    data = data_file.read().replace('\\n', '')\n    data_file.close()\n\n    # Load English tokenizer, tagger, parser and NER\n    nlp = spacy.load(\"en_core_web_sm\")\n    doc = nlp(data)\n\n    # Load and Process Wiki Data\n    if any(ex in range(7,9) for ex in exercise):\n        nlp = spacy.load(\"en_core_web_sm\")\n        wiki_data = pd.read_csv(args.data_dir_stat + \"WikiNews_Train.tsv\", sep='\\t', header=None, usecols=[4, 7, 8, 9, 10])\n        process_wiki()\n\n    # Load function names for each exercise\n    functions = {1: tokenization, 2: words, 3: ngrams, 4: lemmatization, 5: ner,\n                 6: explore_dataset, 7: basic_stat, 8: ling_char}\n\n    for ex in exercise:\n        functions[ex]()\n\n\n\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/AN_analyses.py b/AN_analyses.py
--- a/AN_analyses.py	(revision f7ca392a6e998bf23feb003886281e48cf0a28f8)
+++ b/AN_analyses.py	(date 1650389576743)
@@ -14,7 +14,7 @@
 parser = argparse.ArgumentParser()
 parser.add_argument('--data_dir', default='data/preprocessed/train/', help="Directory containing the dataset")
 parser.add_argument('--data_dir_stat', default='data/original/english/', help="Directory containing the Wiki dataset")
-parser.add_argument('--exercise', default='3')
+parser.add_argument('--exercise', default='4')
 
 #Figure settings
 fig_folder = "images/"
Index: .idea/workspace.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"ChangeListManager\">\n    <list default=\"true\" id=\"4e5420f3-a0e5-4b71-8c71-0dab952bcd35\" name=\"Default Changelist\" comment=\"Addition to 11\">\n      <change beforePath=\"$PROJECT_DIR$/.idea/workspace.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/workspace.xml\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/AN_analyses.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/AN_analyses.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/Assignment 1_IntrotoNLP2022.docx\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/Assignment 1_IntrotoNLP2022.docx\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/TODO_analyses.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/TODO_analyses.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/images/freq_tokens_prob_scatter.png\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/images/freq_tokens_prob_scatter.png\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/images/len_tokens_prob_scatter.png\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/images/len_tokens_prob_scatter.png\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/images/pos_tags_prob_scatter.png\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/images/pos_tags_prob_scatter.png\" afterDir=\"false\" />\n    </list>\n    <option name=\"SHOW_DIALOG\" value=\"false\" />\n    <option name=\"HIGHLIGHT_CONFLICTS\" value=\"true\" />\n    <option name=\"HIGHLIGHT_NON_ACTIVE_CHANGELIST\" value=\"false\" />\n    <option name=\"LAST_RESOLUTION\" value=\"IGNORE\" />\n  </component>\n  <component name=\"FileTemplateManagerImpl\">\n    <option name=\"RECENT_TEMPLATES\">\n      <list>\n        <option value=\"Python Script\" />\n      </list>\n    </option>\n  </component>\n  <component name=\"Git.Settings\">\n    <option name=\"RECENT_GIT_ROOT_PATH\" value=\"$PROJECT_DIR$\" />\n  </component>\n  <component name=\"JupyterTrust\" id=\"2cfff2f0-98f0-4495-a566-164be147bd42\" />\n  <component name=\"MarkdownSettingsMigration\">\n    <option name=\"stateVersion\" value=\"1\" />\n  </component>\n  <component name=\"ProjectId\" id=\"25jqgH0NDSIIQdptWy8GrxgTj4d\" />\n  <component name=\"ProjectViewState\">\n    <option name=\"hideEmptyMiddlePackages\" value=\"true\" />\n    <option name=\"showLibraryContents\" value=\"true\" />\n  </component>\n  <component name=\"PropertiesComponent\">\n    <property name=\"RunOnceActivity.OpenProjectViewOnStart\" value=\"true\" />\n    <property name=\"RunOnceActivity.ShowReadmeOnStart\" value=\"true\" />\n    <property name=\"SHARE_PROJECT_CONFIGURATION_FILES\" value=\"true\" />\n    <property name=\"WebServerToolWindowFactoryState\" value=\"false\" />\n    <property name=\"last_opened_file_path\" value=\"$PROJECT_DIR$\" />\n    <property name=\"settings.editor.selected.configurable\" value=\"com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable\" />\n  </component>\n  <component name=\"RecentsManager\">\n    <key name=\"CopyFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$\" />\n    </key>\n    <key name=\"MoveFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$/data/preprocessed/train\" />\n      <recent name=\"$PROJECT_DIR$/data/preprocessed/test\" />\n      <recent name=\"$PROJECT_DIR$/data/preprocessed/val\" />\n    </key>\n  </component>\n  <component name=\"RunManager\" selected=\"Python.TODO_baselines\">\n    <configuration name=\"AN_analyses\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\n      <module name=\"intro2nlp_assignment1_code\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$\" />\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/AN_analyses.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"TODO_baselines\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\n      <module name=\"intro2nlp_assignment1_code\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$\" />\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/TODO_baselines.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"TODO_detailed_evaluation\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\n      <module name=\"intro2nlp_assignment1_code\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$\" />\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/TODO_detailed_evaluation.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"evaluate\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\n      <module name=\"intro2nlp_assignment1_code\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$\" />\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/evaluate.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"train\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\n      <module name=\"intro2nlp_assignment1_code\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$\" />\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/train.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <recent_temporary>\n      <list>\n        <item itemvalue=\"Python.TODO_baselines\" />\n        <item itemvalue=\"Python.TODO_detailed_evaluation\" />\n        <item itemvalue=\"Python.evaluate\" />\n        <item itemvalue=\"Python.train\" />\n        <item itemvalue=\"Python.AN_analyses\" />\n      </list>\n    </recent_temporary>\n  </component>\n  <component name=\"SpellCheckerSettings\" RuntimeDictionaries=\"0\" Folders=\"0\" CustomDictionaries=\"0\" DefaultDictionary=\"application-level\" UseSingleDictionary=\"true\" transferred=\"true\" />\n  <component name=\"SvnConfiguration\">\n    <configuration />\n  </component>\n  <component name=\"TaskManager\">\n    <task active=\"true\" id=\"Default\" summary=\"Default task\">\n      <changelist id=\"4e5420f3-a0e5-4b71-8c71-0dab952bcd35\" name=\"Default Changelist\" comment=\"\" />\n      <created>1646050952780</created>\n      <option name=\"number\" value=\"Default\" />\n      <option name=\"presentableId\" value=\"Default\" />\n      <updated>1646050952780</updated>\n      <workItem from=\"1646050955347\" duration=\"1808000\" />\n      <workItem from=\"1646052847374\" duration=\"2389000\" />\n      <workItem from=\"1646386011328\" duration=\"4871000\" />\n      <workItem from=\"1647000280044\" duration=\"565000\" />\n      <workItem from=\"1648712195025\" duration=\"4281000\" />\n      <workItem from=\"1649078505569\" duration=\"1471000\" />\n    </task>\n    <task id=\"LOCAL-00001\" summary=\"Adjustment Word doc\">\n      <created>1650358379995</created>\n      <option name=\"number\" value=\"00001\" />\n      <option name=\"presentableId\" value=\"LOCAL-00001\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1650358379995</updated>\n    </task>\n    <task id=\"LOCAL-00002\" summary=\"Adjustments Word\">\n      <created>1650360170214</created>\n      <option name=\"number\" value=\"00002\" />\n      <option name=\"presentableId\" value=\"LOCAL-00002\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1650360170215</updated>\n    </task>\n    <task id=\"LOCAL-00003\" summary=\"Addition to 11\">\n      <created>1650373352040</created>\n      <option name=\"number\" value=\"00003\" />\n      <option name=\"presentableId\" value=\"LOCAL-00003\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1650373352040</updated>\n    </task>\n    <option name=\"localTasksCounter\" value=\"4\" />\n    <servers />\n  </component>\n  <component name=\"TypeScriptGeneratedFilesManager\">\n    <option name=\"version\" value=\"2\" />\n  </component>\n  <component name=\"Vcs.Log.Tabs.Properties\">\n    <option name=\"TAB_STATES\">\n      <map>\n        <entry key=\"MAIN\">\n          <value>\n            <State />\n          </value>\n        </entry>\n      </map>\n    </option>\n  </component>\n  <component name=\"VcsManagerConfiguration\">\n    <MESSAGE value=\"Adjustment Word doc\" />\n    <MESSAGE value=\"Adjustments Word\" />\n    <MESSAGE value=\"Addition to 11\" />\n    <option name=\"LAST_COMMIT_MESSAGE\" value=\"Addition to 11\" />\n  </component>\n  <component name=\"XDebuggerManager\">\n    <breakpoint-manager>\n      <breakpoints>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/build_vocab.py</url>\n          <line>14</line>\n          <option name=\"timeStamp\" value=\"1\" />\n        </line-breakpoint>\n      </breakpoints>\n    </breakpoint-manager>\n  </component>\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/workspace.xml b/.idea/workspace.xml
--- a/.idea/workspace.xml	(revision f7ca392a6e998bf23feb003886281e48cf0a28f8)
+++ b/.idea/workspace.xml	(date 1650443071337)
@@ -1,14 +1,9 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <project version="4">
   <component name="ChangeListManager">
-    <list default="true" id="4e5420f3-a0e5-4b71-8c71-0dab952bcd35" name="Default Changelist" comment="Addition to 11">
+    <list default="true" id="4e5420f3-a0e5-4b71-8c71-0dab952bcd35" name="Default Changelist" comment="Additions word doc">
       <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/AN_analyses.py" beforeDir="false" afterPath="$PROJECT_DIR$/AN_analyses.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/Assignment 1_IntrotoNLP2022.docx" beforeDir="false" afterPath="$PROJECT_DIR$/Assignment 1_IntrotoNLP2022.docx" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/TODO_analyses.py" beforeDir="false" afterPath="$PROJECT_DIR$/TODO_analyses.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/images/freq_tokens_prob_scatter.png" beforeDir="false" afterPath="$PROJECT_DIR$/images/freq_tokens_prob_scatter.png" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/images/len_tokens_prob_scatter.png" beforeDir="false" afterPath="$PROJECT_DIR$/images/len_tokens_prob_scatter.png" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/images/pos_tags_prob_scatter.png" beforeDir="false" afterPath="$PROJECT_DIR$/images/pos_tags_prob_scatter.png" afterDir="false" />
     </list>
     <option name="SHOW_DIALOG" value="false" />
     <option name="HIGHLIGHT_CONFLICTS" value="true" />
@@ -52,7 +47,7 @@
       <recent name="$PROJECT_DIR$/data/preprocessed/val" />
     </key>
   </component>
-  <component name="RunManager" selected="Python.TODO_baselines">
+  <component name="RunManager" selected="Python.AN_analyses">
     <configuration name="AN_analyses" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
       <module name="intro2nlp_assignment1_code" />
       <option name="INTERPRETER_OPTIONS" value="" />
@@ -162,11 +157,11 @@
     </configuration>
     <recent_temporary>
       <list>
+        <item itemvalue="Python.AN_analyses" />
         <item itemvalue="Python.TODO_baselines" />
         <item itemvalue="Python.TODO_detailed_evaluation" />
         <item itemvalue="Python.evaluate" />
         <item itemvalue="Python.train" />
-        <item itemvalue="Python.AN_analyses" />
       </list>
     </recent_temporary>
   </component>
@@ -209,7 +204,14 @@
       <option name="project" value="LOCAL" />
       <updated>1650373352040</updated>
     </task>
-    <option name="localTasksCounter" value="4" />
+    <task id="LOCAL-00004" summary="Additions word doc">
+      <created>1650389179750</created>
+      <option name="number" value="00004" />
+      <option name="presentableId" value="LOCAL-00004" />
+      <option name="project" value="LOCAL" />
+      <updated>1650389179750</updated>
+    </task>
+    <option name="localTasksCounter" value="5" />
     <servers />
   </component>
   <component name="TypeScriptGeneratedFilesManager">
@@ -230,7 +232,8 @@
     <MESSAGE value="Adjustment Word doc" />
     <MESSAGE value="Adjustments Word" />
     <MESSAGE value="Addition to 11" />
-    <option name="LAST_COMMIT_MESSAGE" value="Addition to 11" />
+    <MESSAGE value="Additions word doc" />
+    <option name="LAST_COMMIT_MESSAGE" value="Additions word doc" />
   </component>
   <component name="XDebuggerManager">
     <breakpoint-manager>
